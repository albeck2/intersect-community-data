{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDetVnGnoHR-"
   },
   "source": [
    "# Housing Unit Allocation Full Workflow\n",
    "\n",
    "## Overview\n",
    "Given a building inventory that uses IN-CORE standard columns, run housing unit allocation.\n",
    "This process checks to see if the housing unit inventory is available and if not it will create it.\n",
    "This process checks to see if the address point inventory is available and if not it will create it.\n",
    "\n",
    "With the housing unit inventory and address point inventory created, they will be uploaded to IN-CORE Dataservice.\n",
    "\n",
    "With the required files on IN-CORE Dataservice, the housing unit allocation method will run.\n",
    "Functions are provided to obtain and clean data required for the version 2 Housing Unit Allocation. \n",
    "\n",
    "## Required Inputs\n",
    "Program requires the following inputs:\n",
    "1. Building inventory file from pyincore\n",
    "    - IN-CORE account\n",
    "    \n",
    "## Output Description\n",
    "The output of this workflow is a CSV file with the housing unit inventory allocated to a building inventory using the housing unit allocation model.\n",
    "\n",
    "The output CSV is designed to be used in the Interdependent Networked Community Resilience Modeling Environment (IN-CORE).\n",
    "\n",
    "IN-CORE is an open source python package that can be used to model the resilience of a community. To download IN-CORE, see:\n",
    "\n",
    "https://incore.ncsa.illinois.edu/\n",
    "\n",
    "\n",
    "## Instructions\n",
    "Users can run the workflow by executing each block of code in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Program\n",
    "- program:    ncoda_07cv1_run_HUA_workflow\n",
    "- task:       Start with building inventory and run housing unit allocation algorithm\n",
    "- See github commits for description of program updates\n",
    "- Current Version:    2022-08-29 - v2 workflow\n",
    "- 2022-10-06 - clean up code and test output for Salt Lake City\n",
    "- project:    Interdependent Networked Community Resilience Modeling Environment (IN-CORE), Subtask 5.2 - Social Institutions\n",
    "- funding:\t  NIST Financial Assistance Award Numbers: 70NANB15H044 and 70NANB20H008 \n",
    "- author:     Nathanael Rosenheim\n",
    "\n",
    "- Suggested Citation:\n",
    "Rosenheim, Nathanael (2021) “Detailed Household and Housing Unit Characteristics: Data and Replication Code.” DesignSafe-CI. \n",
    "https://doi.org/10.17603/ds2-jwf6-s535."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd # For reading in shapefiles\n",
    "import numpy as np\n",
    "import sys # For displaying package versions\n",
    "import os # For managing directories and file paths if drive is mounted\n",
    "\n",
    "from pyincore import IncoreClient, Dataset, FragilityService, MappingSet, DataService\n",
    "from pyincore.analyses.buildingdamage.buildingdamage import BuildingDamage\n",
    "\n",
    "from pyincore_viz.geoutil import GeoUtil as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# To reload submodules need to use this magic command to set autoreload on\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# open, read, and execute python program with reusable commands\n",
    "from pyncoda.ncoda_07a_generate_hui import generate_hui_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scooby # Reports Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "  Date: Thu Oct 06 13:24:28 2022 Central Daylight Time\n",
      "\n",
      "                OS : Windows\n",
      "            CPU(s) : 12\n",
      "           Machine : AMD64\n",
      "      Architecture : 64bit\n",
      "               RAM : 31.6 GiB\n",
      "       Environment : Jupyter\n",
      "\n",
      "  Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:50:36) [MSC\n",
      "  v.1929 64 bit (AMD64)]\n",
      "\n",
      "            pandas : 1.5.0\n",
      "             numpy : 1.23.3\n",
      "             scipy : 1.9.1\n",
      "           IPython : 8.5.0\n",
      "        matplotlib : 3.6.0\n",
      "            scooby : 0.5.12\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate report of Python environment\n",
    "print(scooby.Report(additional=['pandas']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nathanael99\\\\MyProjects\\\\IN-CORE\\\\Tasks\\\\PublishHUIv2\\\\HousingUnitInventories_2022-03-03\\\\ReplicationCode\\\\intersect-community-data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check working directory - good practice for relative path access\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncommunities = {'Galveston_TX' : {\\n                    'community_name' : 'Galveston, TX',\\n                    'counties' : { \\n                        1 : {'FIPS Code' : '48167', 'Name' : 'Galveston County, TX'}}}}\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edit Data Dictionary for Community\n",
    "\n",
    "communities = {'SaltLakeCity_UT' : {\n",
    "                    'community_name' : 'Salt Lake City, UT',\n",
    "                    'counties' : { \n",
    "                        1 : {'FIPS Code' : '49035', 'Name' : 'Salt Lake City County, UT'}}}}\n",
    "\n",
    "'''\n",
    "communities = {'Galveston_TX' : {\n",
    "                    'community_name' : 'Galveston, TX',\n",
    "                    'counties' : { \n",
    "                        1 : {'FIPS Code' : '48167', 'Name' : 'Galveston County, TX'}}}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up pyincore and read in data\n",
    "IN-CORE is an open source python package that can be used to model the resilience of a community. To download IN-CORE, see:\n",
    "\n",
    "https://incore.ncsa.illinois.edu/\n",
    "\n",
    "Registration is free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful to IN-CORE services. pyIncore version detected: 1.7.0\n"
     ]
    }
   ],
   "source": [
    "client = IncoreClient()\n",
    "# IN-CORE caches files on the local machine, it might be necessary to clear the memory\n",
    "#client.clear_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data_service object for loading files\n",
    "data_service = DataService(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use existing Housing Unit Inventory or create a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Housing Unit Inventory v2.0.0 data for Salt Lake City, UT\n",
      "Connection successful to IN-CORE services. pyIncore version detected: 1.7.0\n",
      "Number of datasets matching Housing Unit Inventory v2.0.0 data for Salt Lake City, UT: 1\n",
      "Dataset Housing Unit Inventory v2.0.0 data for Salt Lake City, UT already exists in IN-CORE\n",
      "Dataset already exists in IN-CORE with filename hui_v2-0-0_SaltLakeCity_UT_2010_rs1000.csv\n",
      "Use dataset_id: 630e8b03f5438e1f8c51d7c2\n",
      "Dataset already exists on IN-CORE, use dataset_id: 630e8b03f5438e1f8c51d7c2\n"
     ]
    }
   ],
   "source": [
    "version = '2.0.0'\n",
    "version_text = 'v2-0-0'\n",
    "\n",
    "# Save Outputfolder - due to long folder name paths output saved to folder with shorter name\n",
    "# files from this program will be saved with the program name - \n",
    "# this helps to follow the overall workflow\n",
    "outputfolder = \"OutputData\"\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 1000\n",
    "basevintage = 2010\n",
    "\n",
    "generate_hui_df = generate_hui_functions(\n",
    "                    communities =   communities,\n",
    "                    seed =          seed,\n",
    "                    version =       version,\n",
    "                    version_text=   version_text,\n",
    "                    basevintage=    basevintage,\n",
    "                    outputfolder=   outputfolder\n",
    "                    )\n",
    "\n",
    "hui_dataset_id = generate_hui_df.generate_hui_v2_for_incore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Building Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IN-CORE Dataservice has saved the Building Inventory on your local machine: C:\\Users\\nathanael99\\.incore\\cache_data\\648c22dd689743dc9dedf242006adc5a9c21de9a89c016323dccfedef94f7737\\62fea288f5438e1f8c515ef8\\Salt Lake County All Building\\Salt Lake County All Building.shp\n"
     ]
    }
   ],
   "source": [
    "# Building inventory\n",
    "bldg_inv_id = \"62fea288f5438e1f8c515ef8\" # SLC building inventory - Milad Roohi\n",
    "# load building inventory\n",
    "bldg_inv = Dataset.from_data_service(bldg_inv_id, data_service)\n",
    "filename = bldg_inv.get_file_path('shp')\n",
    "print(\"The IN-CORE Dataservice has saved the Building Inventory on your local machine: \"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World.\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bldg_inv_gdf = gpd.read_file(filename)\n",
    "# Check CRS of building inventory\n",
    "bldg_inv_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import CRS\n",
    "# Update CRS to EPSG:4326 if not already in that format\n",
    "if bldg_inv_gdf.crs != CRS.from_epsg(4326):\n",
    "    bldg_inv_gdf = bldg_inv_gdf.to_crs(epsg=4326)\n",
    "    print(\"The CRS of the building inventory has been updated to EPSG:4326\")\n",
    "else:\n",
    "    print(\"The CRS of the building inventory is already in EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Unique ID\n",
    "bldg_inv_gdf[['guid','bldg_id']].astype(str).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_inv_gdf.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Spatial Extent of Building Inventory\n",
    "Need to know which counties are included in the building inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = viz.plot_gdf_map(bldg_inv_gdf,column='dlevel')\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Tract ID to find county FIPS code\n",
    "The first 5 digits of the tract ID are the FIPS code for the county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_inv_gdf['tract_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substring of tractid to get county 5 digit fips code \n",
    "# covert tract_id to string with leading zeros\n",
    "bldg_inv_gdf['tract_id_str'] = bldg_inv_gdf['tract_id'].astype(str).str.zfill(11)\n",
    "bldg_inv_gdf['county'] = bldg_inv_gdf['tract_id_str'].str[:5]\n",
    "bldg_inv_gdf[['tract_id_str','county']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Inventory File has 1 county\n",
    "The Salt Late City building inventory only has 1 county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Counties using spatial extent of data file\n",
    "To Do - use the spatial extent to locate counties in the building inventory.\n",
    "\n",
    "Might be able to merge the building inventory with the block id first to get the county FIPS codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "buffer_dist: buffer distance in degrees for lat/lon around point bounds\n",
    "     - https://en.wikipedia.org/wiki/Decimal_degrees\n",
    "     - example: 0.001 for 1/1000th of a degree or approximately 100 meters\n",
    "     - example: 0.0001 for 1/10000th of a degree or approximately 10 meter\n",
    "'''\n",
    "\n",
    "buffer_dist = 0.001\n",
    "# What is the center of the building inventory?\n",
    "minx = bldg_inv_gdf.bounds.minx.min() - buffer_dist # subtract buffer from minimum values\n",
    "miny = bldg_inv_gdf.bounds.miny.min() - buffer_dist\n",
    "maxx = bldg_inv_gdf.bounds.maxx.max() + buffer_dist\n",
    "maxy = bldg_inv_gdf.bounds.maxy.max() + buffer_dist\n",
    "bldg_inv_gdf_bounds = [minx, miny, maxx, maxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What location should the map be centered on?\n",
    "center_x = (minx + maxx)/2\n",
    "center_y = (miny + maxy)/2\n",
    "print(f'The center of the building inventory data file is located at {center_x} {center_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if Housing Unit Inventory Available on IN-CORE Data Service\n",
    "\n",
    "For more information see:\n",
    "\n",
    "Rosenheim, Nathanael, Roberto Guidotti, Paolo Gardoni & Walter Gillis Peacock. (2019). Integration of detailed household and housing unit characteristic data with critical infrastructure for post-hazard resilience modeling. Sustainable and Resilient Infrastructure. doi.org/10.1080/23789689.2019.1681821\n",
    "\n",
    "Rosenheim, Nathanael (2021) “Detailed Household and Housing Unit Characteristics: Data and Replication Code.” DesignSafe-CI. https://doi.org/10.17603/ds2-jwf6-s535."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for community in communities.keys():\n",
    "    # Create empty container to store outputs for in-core\n",
    "    # Will use these to combine multiple counties\n",
    "    hua_incore_county_df = {}\n",
    "    print(\"Checking Housing Unit Inventory for\",communities[community]['community_name'])\n",
    "    for county in communities[community]['counties'].keys():\n",
    "        state_county = communities[community]['counties'][county]['FIPS Code']\n",
    "        state_county_name  = communities[community]['counties'][county]['Name']\n",
    "        print(state_county_name,': county FIPS Code',state_county)\n",
    "\n",
    "        hui_filename = f'hui_{version_text}_{community}_{basevintage}_rs{seed}'\n",
    "\n",
    "        # Check IN-CORE Data Service for filename\n",
    "        print('Check IN-CORE Data Service for the file',hui_filename)\n",
    "        matched_datasets = data_service.search_datasets(hui_filename)\n",
    "\n",
    "        # Check if matched_datasets is empty\n",
    "        if matched_datasets:\n",
    "            # How many observations in  matched_datasets?\n",
    "            print(f'There are {len(matched_datasets)} datasets matching {hui_filename}')\n",
    "            if len(matched_datasets) == 1:\n",
    "                hui_id = matched_datasets[0]['id']\n",
    "            else:\n",
    "                print(\"There are multiple datasets matching the filename. Please select one.\")\n",
    "                for i, dataset in enumerate(matched_datasets):\n",
    "                    print(i,matched_datasets[i]['dataset']['id'])\n",
    "                hui_id = matched_datasets[int(input(\"Enter dataset number: \"))]['dataset'][\"id\"]\n",
    "            print('Using dataset',hui_id)\n",
    "        else:\n",
    "            print('No matching datasets in IN-CORE Data Service')\n",
    "            print('Creating new dataset')\n",
    "            # Create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing Unit inventory\n",
    "housing_unit_inv_id = \"6262ef3204ce841cbeb30993\"\n",
    "# load housing unit inventory as pandas dataframe\n",
    "housing_unit_inv = Dataset.from_data_service(housing_unit_inv_id, data_service)\n",
    "filename = housing_unit_inv.get_file_path('csv')\n",
    "print(\"The IN-CORE Dataservice has saved the Housing Unit Inventory on your local machine: \"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_unit_inv_df = pd.read_csv(filename, header=\"infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_unit_inv_df['huid'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Address Point Inventory\n",
    "The address point inventory is an intermediate file based on the building inventory. The address point inventory acts as the bridge between the building inventory and the housing unit inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address Point inventory\n",
    "addpt_inv_id = \"60aac382088dfa3b65030b16\"\n",
    "# load housing unit inventory as pandas dataframe\n",
    "addpt_inv = Dataset.from_data_service(addpt_inv_id, data_service)\n",
    "filename = addpt_inv.get_file_path('csv')\n",
    "print(\"The IN-CORE Dataservice has saved the Address Point Inventory on your local machine: \"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addpt_inv_df = pd.read_csv(filename, header=\"infer\")\n",
    "addpt_inv_df['addrptid'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Housing Unit Allocation v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup notebook environment to access Cloned Github Package\n",
    "This notebook uses functions that are in development. The current version of the package is available at:\n",
    "\n",
    "https://github.com/npr99/intersect-community-data\n",
    "\n",
    "Nathanael Rosenheim. (2022). npr99/intersect-community-data. Zenodo. https://doi.org/10.5281/zenodo.6476122\n",
    "\n",
    "A permanent copy of the package and example datasets are available in the DesignSafe-CI repository:\n",
    "\n",
    "Rosenheim, Nathanael (2021) “Detailed Household and Housing Unit Characteristics: Data and Replication Code.” DesignSafe-CI. \n",
    "https://doi.org/10.17603/ds2-jwf6-s535."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To replicate this notebook Clone the Github Package to a folder that is a sibling of this notebook.\n",
    "# To access the sibling package you will need to append the parent directory ('..') to the system path list.\n",
    "# append the path of the directory that includes the github repository.\n",
    "# This step is not required when the package is in a folder below the notebook file.\n",
    "github_code_path  = \"\"\n",
    "sys.path.append(github_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Housing Unit Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of data dictionary for one community with one county\n",
    "communities = {'Lumberton_NC' : {\n",
    "                    'community_name' : 'Lumberton, NC',\n",
    "                    'counties' : { \n",
    "                        1 : {'FIPS Code' : '37155', 'Name' : 'Robeson County, NC'}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '2.0.0'\n",
    "version_text = 'v2-0-0'\n",
    "\n",
    "# Save Outputfolder - due to long folder name paths output saved to folder with shorter name\n",
    "# files from this program will be saved with the program name - \n",
    "# this helps to follow the overall workflow\n",
    "outputfolder = \"OutputData\"\n",
    "# Make directory to save output\n",
    "if not os.path.exists(outputfolder):\n",
    "    os.mkdir(outputfolder)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 1000\n",
    "basevintage = 2010\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Housing Unit Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for community in communities.keys():\n",
    "    # Create empty container to store outputs for in-core\n",
    "    # Will use these to combine multiple counties\n",
    "    hua_incore_county_df = {}\n",
    "    print(\"Setting up Housing Unit Inventory for\",communities[community]['community_name'])\n",
    "    for county in communities[community]['counties'].keys():\n",
    "        state_county = communities[community]['counties'][county]['FIPS Code']\n",
    "        state_county_name  = communities[community]['counties'][county]['Name']\n",
    "        print(state_county_name,': county FIPS Code',state_county)\n",
    "    \n",
    "        outputfolders = directory_design(state_county_name = state_county_name,\n",
    "                                            outputfolder = outputfolder)\n",
    "                                            \n",
    "        generate_df = hua_workflow_functions(\n",
    "            hui_df = housing_unit_inv_df,\n",
    "            addpt_df=addpt_inv_df,\n",
    "            bldg_df=bldg_inv_gdf,\n",
    "            state_county = state_county,\n",
    "            state_county_name= state_county_name,\n",
    "            seed = seed,\n",
    "            version = version,\n",
    "            version_text = version_text,\n",
    "            basevintage = basevintage,\n",
    "            outputfolder = outputfolder,\n",
    "            outputfolders = outputfolders)\n",
    "\n",
    "        # Generate base housing unit inventory\n",
    "        base_hua_df = generate_df.run_hua_workflow(savelog=False)\n",
    "\n",
    "        # Save version for IN-CORE in v2 format\n",
    "        hua_incore_county_df[state_county] = base_hua_df['primary']\n",
    "\n",
    "    # combine multiple counties\n",
    "    hua_incore_df = pd.concat(hua_incore_county_df.values(), \n",
    "                                    ignore_index=True, axis=0)\n",
    "\n",
    "    # Convert HUA to geodataframe format\n",
    "    hua_incore_gdf = gpd.GeoDataFrame(\n",
    "        hua_incore_df, geometry=gpd.points_from_xy(hua_incore_df.x, hua_incore_df.y))\n",
    "\n",
    "    # Merge building inventory with housing unit allocation results\n",
    "    huav2_gdf = pd.merge(left = hua_incore_gdf, \n",
    "                        right = bldg_inv_gdf[['guid','archetype','geometry']], \n",
    "                        on='guid', how='outer')\n",
    "\n",
    "    # If Geometry is null, use X,Y coordinates from Address Point\n",
    "    # use geometry_y unless missing - then use geometry_x\n",
    "    huav2_gdf['geometry'] = huav2_gdf['geometry_y']\n",
    "    huav2_gdf.loc[huav2_gdf['geometry'].isnull(), 'geometry'] = huav2_gdf['geometry_x']\n",
    "    # drop geometry_x and geometry_y columns\n",
    "    huav2_gdf.drop(columns=['geometry_x','geometry_y'], inplace=True)\n",
    "\n",
    "    # Convert Block2010 to string\n",
    "    # fill in missing values\n",
    "    huav2_gdf['Block2010'] = huav2_gdf['Block2010'].fillna(371550000000000)\n",
    "    huav2_gdf['Block2010'] = huav2_gdf['Block2010'].apply(lambda x : str(int(x)).zfill(15))\n",
    "\n",
    "    #Save results for community name\n",
    "    output_filename = f'hua_{version_text}_{community}_{basevintage}_rs{seed}'\n",
    "    csv_filepath = outputfolders['top']+\"/\"+output_filename+'.csv'\n",
    "    savefile = sys.path[0]+\"/\"+csv_filepath\n",
    "    huav2_gdf.to_csv(savefile, index=False)\n",
    "\n",
    "    # Save second set of files in common directory\n",
    "    common_directory = outputfolders['top']+\"/../\"+output_filename\n",
    "    huav2_gdf.to_csv(common_directory+'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check block with missing huid match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyncoda.ncoda_04b_foliummaps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check guid with missing address point id\n",
    "condition1 = (huav2_gdf['guid'] == '099d5476-aaec-42d8-b0d1-e14eee17b373')\n",
    "gdf1 = huav2_gdf.loc[condition1].copy()\n",
    "\n",
    "folium_marker_layer_map(gdf = gdf1,\n",
    "                        gdfvar=\"archetype\",\n",
    "                        layername = \"\",\n",
    "                        color_levels = [0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "IN-CORE_1dv1_Lumberton_CleanLODESdata_2021-05-06.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pyincoreEnv20220411')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3cf6804b2d1d6b39ed9a23bc16482fea2e83abf2b56c0f3b16ad590816ac7680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDetVnGnoHR-"
   },
   "source": [
    "# Housing Unit Allocation v2 Workflow\n",
    "\n",
    "## Overview\n",
    "Functions to obtain and clean data required for the version 2 Housing Unit Allocation. \n",
    "The workflow improves on the [housing unit allocation algorithm found in pyincore](https://github.com/IN-CORE/pyincore/blob/develop/pyincore/analyses/housingunitallocation/housingunitallocation.py).\n",
    "\n",
    "### Found issues in the original HUA:\n",
    "1. Over predicting housing units in a building \n",
    "2. Not assigning one housing unit per structure before assigning more housing units\n",
    "3. Matching extra housing units based on tenure - if there are 2 renters in block then match the extra renter with the other renter.\n",
    "\n",
    "### Resources and references:\n",
    "For an overview of the housing unit allocation method see:\n",
    "\n",
    "Rosenheim, N., Guidotti, R., Gardoni, P., & Peacock, W. G. (2021). Integration of detailed household and housing unit characteristic data with critical infrastructure for post-hazard resilience modeling. Sustainable and Resilient Infrastructure, 6(6), 385-401.\n",
    "\n",
    "## Required Inputs\n",
    "Program requires the following inputs:\n",
    "1. Housing unit inventory file from ncoda_06dv1_run_HUI_v2_workflow.ipynb\n",
    "2. Building inventory file from pyincore\n",
    "    - Future version of ICD will provide tools for generating a building inventory file\n",
    "    - Current version will require users to have an IN-CORE account\n",
    "    \n",
    "## Output Description\n",
    "The output of this workflow is a CSV file with the housing unit inventory merged with a building inventory and a codebook that describes the data.\n",
    "\n",
    "The output CSV is designed to be used in the Interdependent Networked Community Resilience Modeling Environment (IN-CORE) for the housing unit allocation model.\n",
    "\n",
    "IN-CORE is an open source python package that can be used to model the resilience of a community. To download IN-CORE, see:\n",
    "\n",
    "https://incore.ncsa.illinois.edu/\n",
    "\n",
    "\n",
    "## Instructions\n",
    "Users can run the workflow by executing each block of code in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Program\n",
    "- program:    ncoda_06ev2_run_HUA_workflow\n",
    "- task:       Run the Housing Unit Allocation Workflow\n",
    "- See github commits for description of program updates\n",
    "- Current Version:    2022-06-22 - v2 workflow\n",
    "- project:    Interdependent Networked Community Resilience Modeling Environment (IN-CORE), Subtask 5.2 - Social Institutions\n",
    "- funding:\t  NIST Financial Assistance Award Numbers: 70NANB15H044 and 70NANB20H008 \n",
    "- author:     Nathanael Rosenheim\n",
    "\n",
    "- Suggested Citation:\n",
    "Rosenheim, Nathanael (2021) “Detailed Household and Housing Unit Characteristics: Data and Replication Code.” DesignSafe-CI. \n",
    "https://doi.org/10.17603/ds2-jwf6-s535."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd # For reading in shapefiles\n",
    "import numpy as np\n",
    "import sys # For displaying package versions\n",
    "import os # For managing directories and file paths if drive is mounted\n",
    "\n",
    "from pyincore import IncoreClient, Dataset, FragilityService, MappingSet, DataService\n",
    "from pyincore.analyses.buildingdamage.buildingdamage import BuildingDamage\n",
    "\n",
    "from pyincore_viz.geoutil import GeoUtil as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scooby # Reports Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "  Date: Wed Jun 22 12:40:15 2022 Eastern Daylight Time\n",
      "\n",
      "                OS : Windows\n",
      "            CPU(s) : 12\n",
      "           Machine : AMD64\n",
      "      Architecture : 64bit\n",
      "               RAM : 31.6 GiB\n",
      "       Environment : Jupyter\n",
      "\n",
      "  Python 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 05:59:45)\n",
      "  [MSC v.1929 64 bit (AMD64)]\n",
      "\n",
      "            pandas : 1.4.2\n",
      "             numpy : 1.22.3\n",
      "             scipy : 1.8.0\n",
      "           IPython : 8.3.0\n",
      "        matplotlib : 3.5.2\n",
      "            scooby : 0.5.12\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate report of Python environment\n",
    "print(scooby.Report(additional=['pandas']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nathanael99\\\\MyProjects\\\\IN-CORE\\\\Tasks\\\\PublishHUIv2\\\\HousingUnitInventories_2022-03-03\\\\ReplicationCode\\\\intersect-community-data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check working directory - good practice for relative path access\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up pyincore and read in data\n",
    "IN-CORE is an open source python package that can be used to model the resilience of a community. To download IN-CORE, see:\n",
    "\n",
    "https://incore.ncsa.illinois.edu/\n",
    "\n",
    "Registration is free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful to IN-CORE services. pyIncore version detected: 1.4.1\n"
     ]
    }
   ],
   "source": [
    "client = IncoreClient()\n",
    "# IN-CORE caches files on the local machine, it might be necessary to clear the memory\n",
    "#client.clear_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data_service object for loading files\n",
    "data_service = DataService(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Building Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "The IN-CORE Dataservice has saved the Building Inventory on your local machine: C:\\Users\\nathanael99\\.incore\\cache_data\\6036c2a9e379f22e1658d451\\lumberton_building_inventory_w_strcid\\lumberton_building_inventory_w_strcid.shp\n"
     ]
    }
   ],
   "source": [
    "# Building inventory\n",
    "# bldg_inv_id = \"62ab7dcbf328861e25ffea9e\" # New building inventory\n",
    "bldg_inv_id = \"6036c2a9e379f22e1658d451\" # Old building inventory\n",
    "# load building inventory\n",
    "bldg_inv = Dataset.from_data_service(bldg_inv_id, data_service)\n",
    "filename = bldg_inv.get_file_path('shp')\n",
    "print(\"The IN-CORE Dataservice has saved the Building Inventory on your local machine: \"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_inv_gdf = gpd.read_file(filename)\n",
    "\n",
    "from pyproj import CRS\n",
    "bldg_inv_gdf.crs = CRS(\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guid</th>\n",
       "      <td>20091</td>\n",
       "      <td>20091</td>\n",
       "      <td>efd13166-d7a0-476b-ada5-c55cea1f0184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strctid</th>\n",
       "      <td>20091</td>\n",
       "      <td>20091</td>\n",
       "      <td>STefd13166-d7a0-476b-ada5-c55cea1f0184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique                                     top freq\n",
       "guid     20091  20091    efd13166-d7a0-476b-ada5-c55cea1f0184    1\n",
       "strctid  20091  20091  STefd13166-d7a0-476b-ada5-c55cea1f0184    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Unique ID\n",
    "bldg_inv_gdf[['guid','strctid']].astype(str).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Housing Unit Inventory\n",
    "\n",
    "For more information see:\n",
    "\n",
    "Rosenheim, Nathanael, Roberto Guidotti, Paolo Gardoni & Walter Gillis Peacock. (2019). Integration of detailed household and housing unit characteristic data with critical infrastructure for post-hazard resilience modeling. Sustainable and Resilient Infrastructure. doi.org/10.1080/23789689.2019.1681821\n",
    "\n",
    "Rosenheim, Nathanael (2021) “Detailed Household and Housing Unit Characteristics: Data and Replication Code.” DesignSafe-CI. https://doi.org/10.17603/ds2-jwf6-s535."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "The IN-CORE Dataservice has saved the Housing Unit Inventory on your local machine: C:\\Users\\nathanael99\\.incore\\cache_data\\6262ef3204ce841cbeb30993\\hui_v2-0-0_Lumberton_NC_2010_rs1000\\hui_v2-0-0_Lumberton_NC_2010_rs1000.csv\n"
     ]
    }
   ],
   "source": [
    "# Housing Unit inventory\n",
    "housing_unit_inv_id = \"6262ef3204ce841cbeb30993\"\n",
    "# load housing unit inventory as pandas dataframe\n",
    "housing_unit_inv = Dataset.from_data_service(housing_unit_inv_id, data_service)\n",
    "filename = housing_unit_inv.get_file_path('csv')\n",
    "print(\"The IN-CORE Dataservice has saved the Housing Unit Inventory on your local machine: \"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_unit_inv_df = pd.read_csv(filename, header=\"infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                    52801\n",
       "unique                   52801\n",
       "top       B371559601011003H001\n",
       "freq                         1\n",
       "Name: huid, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_unit_inv_df['huid'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Address Point Inventory\n",
    "The address point inventory is an intermediate file based on the building inventory. The address point inventory acts as the bridge between the building inventory and the housing unit inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "The IN-CORE Dataservice has saved the Address Point Inventory on your local machine: C:\\Users\\nathanael99\\.incore\\cache_data\\60aac382088dfa3b65030b16\\IN-CORE_2fv1_Lumberton_Inventories_addresspointinventory\\IN-CORE_2fv1_Lumberton_Inventories_addresspointinventory.csv\n"
     ]
    }
   ],
   "source": [
    "# Address Point inventory\n",
    "addpt_inv_id = \"60aac382088dfa3b65030b16\"\n",
    "# load housing unit inventory as pandas dataframe\n",
    "addpt_inv = Dataset.from_data_service(addpt_inv_id, data_service)\n",
    "filename = addpt_inv.get_file_path('csv')\n",
    "print(\"The IN-CORE Dataservice has saved the Address Point Inventory on your local machine: \"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                              61505\n",
       "unique                                             61505\n",
       "top       ST2d32aeff-7b75-47e6-b7a5-4f4adca4b021AP000000\n",
       "freq                                                   1\n",
       "Name: addrptid, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addpt_inv_df = pd.read_csv(filename, header=\"infer\")\n",
    "addpt_inv_df['addrptid'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Housing Unit Allocation v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup notebook environment to access Cloned Github Package\n",
    "This notebook uses functions that are in development. The current version of the package is available at:\n",
    "\n",
    "https://github.com/npr99/intersect-community-data\n",
    "\n",
    "Nathanael Rosenheim. (2022). npr99/intersect-community-data. Zenodo. https://doi.org/10.5281/zenodo.6476122\n",
    "\n",
    "A permanent copy of the package and example datasets are available in the DesignSafe-CI repository:\n",
    "\n",
    "Rosenheim, Nathanael (2021) “Detailed Household and Housing Unit Characteristics: Data and Replication Code.” DesignSafe-CI. \n",
    "https://doi.org/10.17603/ds2-jwf6-s535."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To replicate this notebook Clone the Github Package to a folder that is a sibling of this notebook.\n",
    "# To access the sibling package you will need to append the parent directory ('..') to the system path list.\n",
    "# append the path of the directory that includes the github repository.\n",
    "# This step is not required when the package is in a folder below the notebook file.\n",
    "github_code_path  = \"\"\n",
    "sys.path.append(github_code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nathanael99\\\\MyProjects\\\\IN-CORE\\\\Tasks\\\\PublishHUIv2\\\\HousingUnitInventories_2022-03-03\\\\ReplicationCode\\\\intersect-community-data'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reload submodules need to use this magic command to set autoreload on\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# open, read, and execute python program with reusable commands\n",
    "from pyncoda.ncoda_05a_hua_functions \\\n",
    "    import hua_workflow_functions\n",
    "from pyncoda.ncoda_00b_directory_design import directory_design\n",
    "from pyncoda.ncoda_06c_Codebook import *\n",
    "from pyncoda.ncoda_04a_Figures import *\n",
    "\n",
    "from pyncoda.CommunitySourceData.api_census_gov.acg_00e_incore_huiv2 \\\n",
    "    import incore_v2_DataStructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Housing Unit Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of data dictionary for one community with one county\n",
    "communities = {'Lumberton_NC' : {\n",
    "                    'community_name' : 'Lumberton, NC',\n",
    "                    'counties' : { \n",
    "                        1 : {'FIPS Code' : '37155', 'Name' : 'Robeson County, NC'}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '2.0.0'\n",
    "version_text = 'v2-0-0'\n",
    "\n",
    "# Save Outputfolder - due to long folder name paths output saved to folder with shorter name\n",
    "# files from this program will be saved with the program name - \n",
    "# this helps to follow the overall workflow\n",
    "outputfolder = \"OutputData\"\n",
    "# Make directory to save output\n",
    "if not os.path.exists(outputfolder):\n",
    "    os.mkdir(outputfolder)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 1000\n",
    "basevintage = 2010\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Housing Unit Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Housing Unit Inventory for Lumberton, NC\n",
      "Robeson County, NC : county FIPS Code 37155\n",
      "\n",
      "***************************************\n",
      "    Run Housing Unit Allocation for Robeson County, NC\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "    Merge housing unit and address point data with first 3 counters.\n",
      "***************************************\n",
      "\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter1', 'ownershp1']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "Initializing primary flag set variable for strctid\n",
      "New flag: strctid_flagsetrm\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3']\n",
      "Initializing geovar flag set variable for strctid at geolevel Block2010\n",
      "New flag: strctid_Block2010_flagsetrm\n",
      "Observations without primary flag set 52801\n",
      "Observations without geovar flag set 52801\n",
      "After updated observations without geovar flag set 52801\n",
      "Setting 52801 flags for data without strctid before merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "4804 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 4804 flags for observations without required variable ownershp1\n",
      "Attempting random merge for 47997 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter1', 'ownershp1', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter1', 'ownershp1']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "Initializing primary flag set variable for strctid\n",
      "New flag: strctid_flagsetrm\n",
      "['addptid', 'Block2010', 'addrptid', 'guid', 'strctid', 'blockid', 'blockidstr', 'plcname10', 'plcgeoid10', 'countyfp10', 'huestimate', 'residential', 'bldgobs', 'flag_ap', 'x', 'y', 'huicounter_addpt', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3']\n",
      "Initializing geovar flag set variable for strctid at geolevel Block2010\n",
      "New flag: strctid_Block2010_flagsetrm\n",
      "Observations without primary flag set 61505\n",
      "Observations without geovar flag set 61505\n",
      "After updated observations without geovar flag set 61505\n",
      "Setting 61505 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "0 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 0 flags for observations without required variable ownershp1\n",
      "Attempting random merge for 61505 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter1', 'ownershp1', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter1', 'ownershp1']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter1', 'ownershp1', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 38251\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 51759\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter1', 'ownershp1', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 99756\n",
      "Observations without geovar flag set 99756\n",
      "After updated observations without geovar flag set 99756\n",
      "Round = 1\n",
      "Setting 9746 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "0 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 0 flags for observations without required variable ownershp1\n",
      "Observations geovar flag set 1 = 9746\n",
      "After Recombine flag set 1 = 9746\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 0\n",
      "Before update results observations flag set 1 = 9746\n",
      "After update observations geovar flag set 1 = 9746\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 14550\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 14550 Observations with predicted strctid\n",
      "Percent left to predict: 72.44\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 0\n",
      "Before update results observations flag set 1 = 9746\n",
      "After update observations geovar flag set 1 = 9746\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 9746\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 9746 Observations with predicted strctid\n",
      "Percent left to predict: 84.15\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  72.443704\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter1', 'ownershp2']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 43055\n",
      "Observations without geovar flag set 38251\n",
      "After updated observations without geovar flag set 38251\n",
      "Setting 0 flags for strctid set before random merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "4804 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Attempting random merge for 38251 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter1', 'ownershp2', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter1', 'ownershp2']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "['addptid', 'Block2010', 'blockid', 'blockidstr', 'plcgeoid10', 'countyfp10', 'residential', 'bldgobs', 'flag_ap', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 51759\n",
      "Observations without geovar flag set 51759\n",
      "After updated observations without geovar flag set 51759\n",
      "Setting 51759 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "0 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Attempting random merge for 51759 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter1', 'ownershp2', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter1', 'ownershp2']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter1', 'ownershp2', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 37605\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 51113\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter1', 'ownershp2', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 89364\n",
      "Observations without geovar flag set 89364\n",
      "After updated observations without geovar flag set 89364\n",
      "Round = 1\n",
      "Setting 646 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "0 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Observations geovar flag set 1 = 646\n",
      "After Recombine flag set 1 = 646\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 9746\n",
      "Before update results observations flag set 1 = 646\n",
      "After update observations geovar flag set 1 = 10392\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 15196\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 15196 Observations with predicted strctid\n",
      "Percent left to predict: 71.22\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 9746\n",
      "Before update results observations flag set 1 = 646\n",
      "After update observations geovar flag set 1 = 10392\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 10392\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 10392 Observations with predicted strctid\n",
      "Percent left to predict: 83.10\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  71.220242\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter1', 'ownershp3']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 42409\n",
      "Observations without geovar flag set 37605\n",
      "After updated observations without geovar flag set 37605\n",
      "Setting 0 flags for strctid set before random merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "4804 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Attempting random merge for 37605 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter1', 'ownershp3', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter1', 'ownershp3']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "['addptid', 'Block2010', 'blockid', 'blockidstr', 'plcgeoid10', 'countyfp10', 'residential', 'bldgobs', 'flag_ap', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 51113\n",
      "Observations without geovar flag set 51113\n",
      "After updated observations without geovar flag set 51113\n",
      "Setting 51113 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "0 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Attempting random merge for 51113 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter1', 'ownershp3', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter1', 'ownershp3']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter1', 'ownershp3', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 32617\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 46125\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter1', 'ownershp3', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 83730\n",
      "Observations without geovar flag set 83730\n",
      "After updated observations without geovar flag set 83730\n",
      "Round = 1\n",
      "Setting 4988 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter1\n",
      "0 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter1\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Observations geovar flag set 1 = 4988\n",
      "After Recombine flag set 1 = 4988\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 10392\n",
      "Before update results observations flag set 1 = 4988\n",
      "After update observations geovar flag set 1 = 15380\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 20184\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 20184 Observations with predicted strctid\n",
      "Percent left to predict: 61.77\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 10392\n",
      "Before update results observations flag set 1 = 4988\n",
      "After update observations geovar flag set 1 = 15380\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 15380\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 15380 Observations with predicted strctid\n",
      "Percent left to predict: 74.99\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  61.773451\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "\n",
      "***************************************\n",
      "   Update Predicted Tenure.\n",
      "***************************************\n",
      "\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter2', 'ownershp1']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 37421\n",
      "Observations without geovar flag set 32617\n",
      "After updated observations without geovar flag set 32617\n",
      "Setting 0 flags for strctid set before random merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "4804 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp1\n",
      "Attempting random merge for 32617 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter2', 'ownershp1', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter2', 'ownershp1']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "['addptid', 'Block2010', 'blockid', 'blockidstr', 'plcgeoid10', 'countyfp10', 'residential', 'bldgobs', 'flag_ap', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 46125\n",
      "Observations without geovar flag set 46125\n",
      "After updated observations without geovar flag set 46125\n",
      "Setting 46125 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "0 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp1\n",
      "Attempting random merge for 46125 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter2', 'ownershp1', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter2', 'ownershp1']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter2', 'ownershp1', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 31808\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 45316\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter2', 'ownershp1', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 77933\n",
      "Observations without geovar flag set 77933\n",
      "After updated observations without geovar flag set 77933\n",
      "Round = 1\n",
      "Setting 809 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "0 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp1\n",
      "Observations geovar flag set 1 = 809\n",
      "After Recombine flag set 1 = 809\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 15380\n",
      "Before update results observations flag set 1 = 809\n",
      "After update observations geovar flag set 1 = 16189\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 20993\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 20993 Observations with predicted strctid\n",
      "Percent left to predict: 60.24\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 15380\n",
      "Before update results observations flag set 1 = 809\n",
      "After update observations geovar flag set 1 = 16189\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 16189\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 16189 Observations with predicted strctid\n",
      "Percent left to predict: 73.68\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  60.241283\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter2', 'ownershp2']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 36612\n",
      "Observations without geovar flag set 31808\n",
      "After updated observations without geovar flag set 31808\n",
      "Setting 0 flags for strctid set before random merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "4804 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Attempting random merge for 31808 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter2', 'ownershp2', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter2', 'ownershp2']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "['addptid', 'Block2010', 'blockid', 'blockidstr', 'plcgeoid10', 'countyfp10', 'residential', 'bldgobs', 'flag_ap', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 45316\n",
      "Observations without geovar flag set 45316\n",
      "After updated observations without geovar flag set 45316\n",
      "Setting 45316 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "0 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Attempting random merge for 45316 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter2', 'ownershp2', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter2', 'ownershp2']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter2', 'ownershp2', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 31394\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 44902\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter2', 'ownershp2', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 76710\n",
      "Observations without geovar flag set 76710\n",
      "After updated observations without geovar flag set 76710\n",
      "Round = 1\n",
      "Setting 414 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "0 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Observations geovar flag set 1 = 414\n",
      "After Recombine flag set 1 = 414\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16189\n",
      "Before update results observations flag set 1 = 414\n",
      "After update observations geovar flag set 1 = 16603\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 21407\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 21407 Observations with predicted strctid\n",
      "Percent left to predict: 59.46\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16189\n",
      "Before update results observations flag set 1 = 414\n",
      "After update observations geovar flag set 1 = 16603\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 16603\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 16603 Observations with predicted strctid\n",
      "Percent left to predict: 73.01\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  59.457207\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter2', 'ownershp3']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 36198\n",
      "Observations without geovar flag set 31394\n",
      "After updated observations without geovar flag set 31394\n",
      "Setting 0 flags for strctid set before random merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "4804 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Attempting random merge for 31394 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter2', 'ownershp3', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter2', 'ownershp3']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "['addptid', 'Block2010', 'blockid', 'blockidstr', 'plcgeoid10', 'countyfp10', 'residential', 'bldgobs', 'flag_ap', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 44902\n",
      "Observations without geovar flag set 44902\n",
      "After updated observations without geovar flag set 44902\n",
      "Setting 44902 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "0 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Attempting random merge for 44902 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter2', 'ownershp3', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter2', 'ownershp3']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter2', 'ownershp3', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 31220\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 44728\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter2', 'ownershp3', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 76122\n",
      "Observations without geovar flag set 76122\n",
      "After updated observations without geovar flag set 76122\n",
      "Round = 1\n",
      "Setting 174 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter2\n",
      "0 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter2\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Observations geovar flag set 1 = 174\n",
      "After Recombine flag set 1 = 174\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16603\n",
      "Before update results observations flag set 1 = 174\n",
      "After update observations geovar flag set 1 = 16777\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 21581\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 21581 Observations with predicted strctid\n",
      "Percent left to predict: 59.13\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16603\n",
      "Before update results observations flag set 1 = 174\n",
      "After update observations geovar flag set 1 = 16777\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 16777\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 16777 Observations with predicted strctid\n",
      "Percent left to predict: 72.72\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  59.127668\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "\n",
      "***************************************\n",
      "   Update Predicted Tenure.\n",
      "***************************************\n",
      "\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter3', 'ownershp1']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 36024\n",
      "Observations without geovar flag set 31220\n",
      "After updated observations without geovar flag set 31220\n",
      "Setting 0 flags for strctid set before random merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "4804 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp1\n",
      "Attempting random merge for 31220 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter3', 'ownershp1', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter3', 'ownershp1']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "['addptid', 'Block2010', 'blockid', 'blockidstr', 'plcgeoid10', 'countyfp10', 'residential', 'bldgobs', 'flag_ap', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 44728\n",
      "Observations without geovar flag set 44728\n",
      "After updated observations without geovar flag set 44728\n",
      "Setting 44728 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "0 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp1\n",
      "Attempting random merge for 44728 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter3', 'ownershp1', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter3', 'ownershp1']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter3', 'ownershp1', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 31220\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 44728\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter3', 'ownershp1', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 75948\n",
      "Observations without geovar flag set 75948\n",
      "After updated observations without geovar flag set 75948\n",
      "Round = 1\n",
      "Setting 0 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "0 observations do not have required variable ownershp1\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp1\n",
      "Observations geovar flag set 1 = 0\n",
      "After Recombine flag set 1 = 0\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16777\n",
      "Before update results observations flag set 1 = 0\n",
      "After update observations geovar flag set 1 = 16777\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 21581\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 21581 Observations with predicted strctid\n",
      "Percent left to predict: 59.13\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16777\n",
      "Before update results observations flag set 1 = 0\n",
      "After update observations geovar flag set 1 = 16777\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 16777\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 16777 Observations with predicted strctid\n",
      "Percent left to predict: 72.72\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  59.127668\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter3', 'ownershp2']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 36024\n",
      "Observations without geovar flag set 31220\n",
      "After updated observations without geovar flag set 31220\n",
      "Setting 0 flags for strctid set before random merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "4804 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Attempting random merge for 31220 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter3', 'ownershp2', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter3', 'ownershp2']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "['addptid', 'Block2010', 'blockid', 'blockidstr', 'plcgeoid10', 'countyfp10', 'residential', 'bldgobs', 'flag_ap', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 44728\n",
      "Observations without geovar flag set 44728\n",
      "After updated observations without geovar flag set 44728\n",
      "Setting 44728 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "0 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Attempting random merge for 44728 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter3', 'ownershp2', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter3', 'ownershp2']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter3', 'ownershp2', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 31002\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 44510\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter3', 'ownershp2', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 75730\n",
      "Observations without geovar flag set 75730\n",
      "After updated observations without geovar flag set 75730\n",
      "Round = 1\n",
      "Setting 218 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "0 observations do not have required variable ownershp2\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp2\n",
      "Observations geovar flag set 1 = 218\n",
      "After Recombine flag set 1 = 218\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16777\n",
      "Before update results observations flag set 1 = 218\n",
      "After update observations geovar flag set 1 = 16995\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 21799\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 21799 Observations with predicted strctid\n",
      "Percent left to predict: 58.71\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16777\n",
      "Before update results observations flag set 1 = 218\n",
      "After update observations geovar flag set 1 = 16995\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 16995\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 16995 Observations with predicted strctid\n",
      "Percent left to predict: 72.37\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  58.714797\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "Round 1\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Performing random merge at geography level: Block\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Attempt to merge hui on all common group vars.\n",
      "\n",
      "***************************************\n",
      "***************************************\n",
      "\n",
      "Running random merge by ['Block2010', 'huicounter3', 'ownershp3']\n",
      "\n",
      "***************************************\n",
      "    Setting up  primary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name huid\n",
      "Primary key variable huid is unique.\n",
      "Primary key huid has no missing values\n",
      "['huid', 'Block2010', 'blockid', 'bgid', 'tractid', 'FIPScounty', 'numprec', 'ownershp', 'race', 'hispan', 'family', 'vacancy', 'gqtype', 'incomegroup', 'hhinc', 'randincome', 'poverty', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 35806\n",
      "Observations without geovar flag set 31002\n",
      "After updated observations without geovar flag set 31002\n",
      "Setting 0 flags for strctid set before random merge.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "4804 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Attempting random merge for 31002 primary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing primary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['huid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter3', 'ownershp3', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter3', 'ownershp3']\n",
      "\n",
      "***************************************\n",
      "    Setting up  secondary data with primary key and flags\n",
      "***************************************\n",
      "\n",
      "Adding Block2010 to column list\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Geolevels available []\n",
      "Geolvarids available ['Block2010']\n",
      "Adding Block2010 expected length 15\n",
      "Dataframe has Block 2010 for new geovar Block2010\n",
      "Confirming Block2010 has expected length.\n",
      "Longest Block2010 : 371559620022133\n",
      "Block2010 Expected Length 15 Available Length 15\n",
      "Checking primary key name addptid\n",
      "Primary key variable addptid is unique.\n",
      "Primary key addptid has no missing values\n",
      "['addptid', 'Block2010', 'blockid', 'blockidstr', 'plcgeoid10', 'countyfp10', 'residential', 'bldgobs', 'flag_ap', 'huicounter1', 'huicounter2', 'huicounter3', 'ownershp1', 'ownershp2', 'ownershp3', 'strctid', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y']\n",
      "Observations without primary flag set 44510\n",
      "Observations without geovar flag set 44510\n",
      "After updated observations without geovar flag set 44510\n",
      "Setting 44510 flags for strctid secondary data not used.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "0 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Attempting random merge for 44510 secondary observations.\n",
      "\n",
      "***************************************\n",
      "    Preparing secondary by NA data for random merge.\n",
      "***************************************\n",
      "\n",
      "Sorting by  ['addptid']\n",
      "Sorting before random merge order by ['Block2010', 'huicounter3', 'ownershp3', 'random_order']\n",
      "Generating random merge order by ['Block2010', 'huicounter3', 'ownershp3']\n",
      "NA\n",
      "\n",
      "***************************************\n",
      "    Random Merge primary with secondary by NA\n",
      "***************************************\n",
      "\n",
      "Check merge vars includes geovarid: ['Block2010', 'huicounter3', 'ownershp3', 'random_mergeorder']\n",
      "Primary data frame has extra strctid  observations with no match: 31002\n",
      "Observations with no match filled with -999\n",
      "Merge found extra strctid  observations: 44510\n",
      "\n",
      "***************************************\n",
      "    Set Flags after Merge\n",
      "***************************************\n",
      "\n",
      "['huid', 'Block2010', 'huicounter3', 'ownershp3', 'random_mergeorder', 'addptid', 'strctid', 'addrptid', 'guid', 'huestimate', 'huicounter_addpt', 'plcname10', 'x', 'y', 'check_merge', 'strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Observations without primary flag set 75512\n",
      "Observations without geovar flag set 75512\n",
      "After updated observations without geovar flag set 75512\n",
      "Round = 1\n",
      "Setting 0 flags for observations set by random merge using both primary and secondary data.\n",
      "Setting 0 flags for observations set by random merge using only primary data.\n",
      "0 observations do not have required variable Block2010\n",
      "0 observations do not have required variable huicounter3\n",
      "0 observations do not have required variable ownershp3\n",
      "Setting 0 flags for observations without required variable Block2010\n",
      "Setting 0 flags for observations without required variable huicounter3\n",
      "Setting 0 flags for observations without required variable ownershp3\n",
      "Observations geovar flag set 1 = 0\n",
      "After Recombine flag set 1 = 0\n",
      "\n",
      "***************************************\n",
      "   Generate output data\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16995\n",
      "Before update results observations flag set 1 = 0\n",
      "After update observations geovar flag set 1 = 16995\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for primary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 21799\n",
      "Input and output data have the same length 52801\n",
      "Outputdata has 21799 Observations with predicted strctid\n",
      "Percent left to predict: 58.71\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "Flag vars available ['strctid_flagsetrm', 'strctid_Block2010_flagsetrm']\n",
      "Before update output_df observations flag set 1 = 16995\n",
      "Before update results observations flag set 1 = 0\n",
      "After update observations geovar flag set 1 = 16995\n",
      "\n",
      "***************************************\n",
      "    Check random merge results for secondary data.\n",
      "***************************************\n",
      "\n",
      "Check by geovar flag strctid_Block2010_flagsetrm\n",
      "Observations flag not equal to 0 16995\n",
      "Input and output data have the same length 61505\n",
      "Outputdata has 16995 Observations with predicted strctid\n",
      "Percent left to predict: 72.37\n",
      "\n",
      "***************************************\n",
      "    Overwrite input data with update output data.\n",
      "***************************************\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "Percent left to predict:  58.714797\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "***************************************\n",
      "    Random merge almost complete.\n",
      "***************************************\n",
      "\n",
      "Check primary and secondary files to understand why merge is not complete\n",
      "\n",
      "***************************************\n",
      "   Update Predicted Tenure.\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "    Merge housing unit and address point data with first no counters.\n",
      "***************************************\n",
      "\n",
      "File OutputData/RobesonCounty_NC/04_RandomMerge/hui_addpt_guidr2_37155_2010_rs1000_primary.csv Already exists - Skipping Random Merge.\n",
      "File hui_addpt_guidr2_37155_2010_rs1000_secondary Already exists - Skipping Random Merge.\n"
     ]
    }
   ],
   "source": [
    "for community in communities.keys():\n",
    "    # Create empty container to store outputs for in-core\n",
    "    # Will use these to combine multiple counties\n",
    "    hua_incore_county_df = {}\n",
    "    print(\"Setting up Housing Unit Inventory for\",communities[community]['community_name'])\n",
    "    for county in communities[community]['counties'].keys():\n",
    "        state_county = communities[community]['counties'][county]['FIPS Code']\n",
    "        state_county_name  = communities[community]['counties'][county]['Name']\n",
    "        print(state_county_name,': county FIPS Code',state_county)\n",
    "    \n",
    "        outputfolders = directory_design(state_county_name = state_county_name,\n",
    "                                            outputfolder = outputfolder)\n",
    "                                            \n",
    "        generate_df = hua_workflow_functions(\n",
    "            hui_df = housing_unit_inv_df,\n",
    "            addpt_df=addpt_inv_df,\n",
    "            bldg_df=bldg_inv_gdf,\n",
    "            state_county = state_county,\n",
    "            state_county_name= state_county_name,\n",
    "            seed = seed,\n",
    "            version = version,\n",
    "            version_text = version_text,\n",
    "            basevintage = basevintage,\n",
    "            outputfolder = outputfolder,\n",
    "            outputfolders = outputfolders)\n",
    "\n",
    "        # Generate base housing unit inventory\n",
    "        base_hua_df = generate_df.run_hua_workflow(savelog=False)\n",
    "\n",
    "        # Save version for IN-CORE in v2 format\n",
    "        hua_incore_county_df[state_county] = base_hua_df['primary']\n",
    "\n",
    "    # combine multiple counties\n",
    "    hua_incore_df = pd.concat(hua_incore_county_df.values(), \n",
    "                                    ignore_index=True, axis=0)\n",
    "\n",
    "    # Convert HUA to geodataframe format\n",
    "    hua_incore_gdf = gpd.GeoDataFrame(\n",
    "        hua_incore_df, geometry=gpd.points_from_xy(hua_incore_df.x, hua_incore_df.y))\n",
    "\n",
    "    # Merge building inventory with housing unit allocation results\n",
    "    huav2_gdf = pd.merge(left = hua_incore_gdf, \n",
    "                        right = bldg_inv_gdf[['guid','archetype','geometry']], \n",
    "                        on='guid', how='outer')\n",
    "\n",
    "    # If Geometry is null, use X,Y coordinates from Address Point\n",
    "    # use geometry_y unless missing - then use geometry_x\n",
    "    huav2_gdf['geometry'] = huav2_gdf['geometry_y']\n",
    "    huav2_gdf.loc[huav2_gdf['geometry'].isnull(), 'geometry'] = huav2_gdf['geometry_x']\n",
    "    # drop geometry_x and geometry_y columns\n",
    "    huav2_gdf.drop(columns=['geometry_x','geometry_y'], inplace=True)\n",
    "\n",
    "    # Convert Block2010 to string\n",
    "    # fill in missing values\n",
    "    huav2_gdf['Block2010'] = huav2_gdf['Block2010'].fillna(371550000000000)\n",
    "    huav2_gdf['Block2010'] = huav2_gdf['Block2010'].apply(lambda x : str(int(x)).zfill(15))\n",
    "\n",
    "    #Save results for community name\n",
    "    output_filename = f'hua_{version_text}_{community}_{basevintage}_rs{seed}'\n",
    "    csv_filepath = outputfolders['top']+\"/\"+output_filename+'.csv'\n",
    "    savefile = sys.path[0]+\"/\"+csv_filepath\n",
    "    huav2_gdf.to_csv(savefile, index=False)\n",
    "\n",
    "    # Save second set of files in common directory\n",
    "    common_directory = outputfolders['top']+\"/../\"+output_filename\n",
    "    huav2_gdf.to_csv(common_directory+'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyncoda.ncoda_04b_foliummaps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>huid</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>B371559608012070H004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guid</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addrptid</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique                   top freq\n",
       "huid         4      4  B371559608012070H004    1\n",
       "guid         4      4                   nan    1\n",
       "addrptid     4      4                   nan    1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condition 1  GUID is not missing\n",
    "condition1 = (huav2_gdf['Block2010'] == '371559608012070')\n",
    "gdf1 = huav2_gdf.loc[condition1].copy()\n",
    "gdf1[['huid','guid','addrptid']].astype(str).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    
        <script>
            L_NO_TOUCH = false;
            L_DISABLE_3D = false;
        </script>
    
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.6.0/dist/leaflet.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.6.0/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css"/>
    
            <meta name="viewport" content="width=device-width,
                initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
            <style>
                #map_d83679442ab24df99709ae019565c600 {
                    position: relative;
                    width: 100.0%;
                    height: 100.0%;
                    left: 0.0%;
                    top: 0.0%;
                }
            </style>
        
    <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet-minimap/3.6.1/Control.MiniMap.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet-minimap/3.6.1/Control.MiniMap.css"/>
</head>
<body>    
    
            <div class="folium-map" id="map_d83679442ab24df99709ae019565c600" ></div>
        
</body>
<script>    
    
            var map_d83679442ab24df99709ae019565c600 = L.map(
                "map_d83679442ab24df99709ae019565c600",
                {
                    center: [34.62548166006548, -79.03560109209529],
                    crs: L.CRS.EPSG3857,
                    zoom: 16,
                    zoomControl: true,
                    preferCanvas: false,
                }
            );

            

        
    
            var tile_layer_3d42fbd76c8a4a55bdca7341e897460b = L.tileLayer(
                "https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png",
                {"attribution": "Data by \u0026copy; \u003ca href=\"http://openstreetmap.org\"\u003eOpenStreetMap\u003c/a\u003e, under \u003ca href=\"http://www.openstreetmap.org/copyright\"\u003eODbL\u003c/a\u003e.", "detectRetina": false, "maxNativeZoom": 18, "maxZoom": 18, "minZoom": 0, "noWrap": false, "opacity": 1, "subdomains": "abc", "tms": false}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var feature_group_e60a28a7f163459b9b17d1daf316dff8 = L.featureGroup(
                {}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var marker_9822142bdb884268b6204b5035e9ba70 = L.marker(
                [34.625696865159306, -79.03561143707343],
                {}
            ).addTo(feature_group_e60a28a7f163459b9b17d1daf316dff8);
        
    
            var icon_6a045a60821541149d67aea566e809d2 = L.AwesomeMarkers.icon(
                {"extraClasses": "fa-rotate-0", "icon": "home", "iconColor": "white", "markerColor": "red", "prefix": "glyphicon"}
            );
            marker_9822142bdb884268b6204b5035e9ba70.setIcon(icon_6a045a60821541149d67aea566e809d2);
        
    
        var popup_61007f82046540118d9012db605ea4dc = L.popup({"maxWidth": "100%"});

        
            var html_f0392e8a6aef4c3c88906f668d475961 = $(`<div id="html_f0392e8a6aef4c3c88906f668d475961" style="width: 100.0%; height: 100.0%;">1.0</div>`)[0];
            popup_61007f82046540118d9012db605ea4dc.setContent(html_f0392e8a6aef4c3c88906f668d475961);
        

        marker_9822142bdb884268b6204b5035e9ba70.bindPopup(popup_61007f82046540118d9012db605ea4dc)
        ;

        
    
    
            var feature_group_24921e982492489bb1121dd7d50bc533 = L.featureGroup(
                {}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var feature_group_9da7369991a747fa96d6236a8d1c7d6b = L.featureGroup(
                {}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var marker_0736802922fe474eb6739e5acf366e93 = L.marker(
                [34.62526645497166, -79.03587074862779],
                {}
            ).addTo(feature_group_9da7369991a747fa96d6236a8d1c7d6b);
        
    
            var icon_5c974d4637924128800a449594dfaa05 = L.AwesomeMarkers.icon(
                {"extraClasses": "fa-rotate-0", "icon": "home", "iconColor": "white", "markerColor": "green", "prefix": "glyphicon"}
            );
            marker_0736802922fe474eb6739e5acf366e93.setIcon(icon_5c974d4637924128800a449594dfaa05);
        
    
        var popup_48ea137d811c422fb35d433637551e1f = L.popup({"maxWidth": "100%"});

        
            var html_d86218b8bd2c46f7b567960577a32300 = $(`<div id="html_d86218b8bd2c46f7b567960577a32300" style="width: 100.0%; height: 100.0%;">3.0</div>`)[0];
            popup_48ea137d811c422fb35d433637551e1f.setContent(html_d86218b8bd2c46f7b567960577a32300);
        

        marker_0736802922fe474eb6739e5acf366e93.bindPopup(popup_48ea137d811c422fb35d433637551e1f)
        ;

        
    
    
            var marker_ca0ae40fb4634315b9552889721014e3 = L.marker(
                [34.625604981303105, -79.0353314355628],
                {}
            ).addTo(feature_group_9da7369991a747fa96d6236a8d1c7d6b);
        
    
            var icon_9116bf6157424a529fc79832648913b2 = L.AwesomeMarkers.icon(
                {"extraClasses": "fa-rotate-0", "icon": "home", "iconColor": "white", "markerColor": "green", "prefix": "glyphicon"}
            );
            marker_ca0ae40fb4634315b9552889721014e3.setIcon(icon_9116bf6157424a529fc79832648913b2);
        
    
        var popup_d68c3d0f88ef415dade9fdc8bcc6b1aa = L.popup({"maxWidth": "100%"});

        
            var html_b97b6f8431dc431ab0f4b93a0268c29f = $(`<div id="html_b97b6f8431dc431ab0f4b93a0268c29f" style="width: 100.0%; height: 100.0%;">3.0</div>`)[0];
            popup_d68c3d0f88ef415dade9fdc8bcc6b1aa.setContent(html_b97b6f8431dc431ab0f4b93a0268c29f);
        

        marker_ca0ae40fb4634315b9552889721014e3.bindPopup(popup_d68c3d0f88ef415dade9fdc8bcc6b1aa)
        ;

        
    
    
            var feature_group_ec8df45ce9bc4ba38b7628b9b8c6926f = L.featureGroup(
                {}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var feature_group_21d15aac6bb9460084f9f3c12f4d2098 = L.featureGroup(
                {}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var feature_group_3c2d4cb5ad334b2bbc04c418f2cdf24f = L.featureGroup(
                {}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var feature_group_d2bd0e5440b441d883956c5e85c31f0b = L.featureGroup(
                {}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var layer_control_5e8fe99e97734b1183e8c667ef868959 = {
                base_layers : {
                    "openstreetmap" : tile_layer_3d42fbd76c8a4a55bdca7341e897460b,
                },
                overlays :  {
                    "households 1" : feature_group_e60a28a7f163459b9b17d1daf316dff8,
                    "households 2" : feature_group_24921e982492489bb1121dd7d50bc533,
                    "households 3" : feature_group_9da7369991a747fa96d6236a8d1c7d6b,
                    "households 4" : feature_group_ec8df45ce9bc4ba38b7628b9b8c6926f,
                    "households 5" : feature_group_21d15aac6bb9460084f9f3c12f4d2098,
                    "households 6" : feature_group_3c2d4cb5ad334b2bbc04c418f2cdf24f,
                    "households 7" : feature_group_d2bd0e5440b441d883956c5e85c31f0b,
                },
            };
            L.control.layers(
                layer_control_5e8fe99e97734b1183e8c667ef868959.base_layers,
                layer_control_5e8fe99e97734b1183e8c667ef868959.overlays,
                {"autoZIndex": false, "collapsed": false, "position": "topright"}
            ).addTo(map_d83679442ab24df99709ae019565c600);
        
    
            var tile_layer_f35eba636ef74ad5833dbf30852ead39 = L.tileLayer(
                "https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png",
                {"attribution": "Data by \u0026copy; \u003ca href=\"http://openstreetmap.org\"\u003eOpenStreetMap\u003c/a\u003e, under \u003ca href=\"http://www.openstreetmap.org/copyright\"\u003eODbL\u003c/a\u003e.", "detectRetina": false, "maxNativeZoom": 18, "maxZoom": 18, "minZoom": 0, "noWrap": false, "opacity": 1, "subdomains": "abc", "tms": false}
            );
            var mini_map_0fac02e33c004a3cb92b114ce5fdb959 = new L.Control.MiniMap(
                tile_layer_f35eba636ef74ad5833dbf30852ead39,
                {"autoToggleDisplay": false, "centerFixed": false, "collapsedHeight": 25, "collapsedWidth": 25, "height": 150, "minimized": false, "position": "bottomright", "toggleDisplay": false, "width": 150, "zoomAnimation": false, "zoomLevelOffset": -5}
            );
            map_d83679442ab24df99709ae019565c600.addControl(mini_map_0fac02e33c004a3cb92b114ce5fdb959);
        
    
            map_d83679442ab24df99709ae019565c600.fitBounds(
                [[34.62526645497166, -79.03587074862779], [34.625696865159306, -79.0353314355628]],
                {}
            );
        
</script>\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1b5527742b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folium_marker_layer_map(gdf = gdf1,\n",
    "                        gdfvar = 'numprec',\n",
    "                        layername = \"households\",\n",
    "                        color_levels = [0,1,2,3,4,5,6,7])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "IN-CORE_1dv1_Lumberton_CleanLODESdata_2021-05-06.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pyincoreEnv20220411')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3cf6804b2d1d6b39ed9a23bc16482fea2e83abf2b56c0f3b16ad590816ac7680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
